# LLM Finetune ç½‘é¡µæ ¼å¼ä¸€é”®å¼çš„å…¨æµç¨‹å¹³å°ï¼ŒåŒ…æ‹¬æ•°æ®ä¸Šä¼ ã€å¾®è°ƒè®­ç»ƒã€æ¨¡å‹åˆå¹¶ã€æ¨¡å‹éƒ¨ç½²æœåŠ¡ç­‰ï¼Œæ— éœ€pythonå’Œshellå¼€å‘


[![GitHub Code License](https://img.shields.io/github/license/simonlisiyu/llm_finetune)](LICENSE)
[![GitHub last commit](https://img.shields.io/github/last-commit/simonlisiyu/llm_finetune)](https://github.com/simonlisiyu/llm_finetune/commits/main)

ğŸ‘‹ åŠ æˆ‘çš„[å¾®ä¿¡](wechat.jpg)ã€‚

## æ›´æ–°æ—¥å¿—

[23/11/14]
é…ç½®è¿›ä¸€æ­¥ç²¾ç®€ï¼ŒåŸºæœ¬0é…ç½®å¯åŠ¨ï¼›
æ”¯æŒchatglm3, qwen, intern, xverse, mistralï¼›
æ”¯æŒå¤§æ¨¡å‹è¯„ä¼°ï¼Œæ”¯æŒC-EVALã€MMLUã€CMMLUï¼›
è®­ç»ƒå’Œåˆå¹¶æ”¯æŒæŒ‡å®šcheckpointè·¯å¾„ï¼›
ç³»ç»Ÿç›‘æ§å¢åŠ gpuè¿›ç¨‹å’ŒdockeråŒ¹é…ï¼›

[23/10/28]
ä»£ç é‡æ„ï¼Œæ”¯æŒæ•´ä½“ä»£ç æ•´åˆåˆ°alita-traineré‡Œï¼›
yamlé…ç½®æ–‡ä»¶ç²¾ç®€è§„æ•´ï¼Œå¤šæ¨¡å‹çš„è®­ç»ƒã€åˆå¹¶è„šæœ¬åˆå¹¶ç»Ÿä¸€ï¼›
æ¨¡å‹éƒ¨ç½²æœåŠ¡bugä¿®å¤ï¼›
æ”¯æŒå¤§æ¨¡å‹è¯„ä¼°ï¼Œæ”¯æŒBLEU-4ã€ROUGE-1/2/Lï¼›
æ”¯æŒå¾®è°ƒè®­ç»ƒåçš„å¤§æ¨¡å‹ä½œä¸ºè®­ç»ƒæ¨¡å‹å†è®­ç»ƒï¼›
ç³»ç»Ÿç›‘æ§é™¤gpuï¼Œæ”¯æŒcpuã€memå’Œdiskç›‘æ§ï¼›

[23/09/28]
æ”¯æŒbaichuanã€llama2ã€llamaã€glm2ç­‰å¤§æ¨¡å‹ï¼Œæ”¯æŒQLoRAï¼›
æ”¯æŒgpué¢„è§ˆã€å¤§æ¨¡å‹å¾®è°ƒè®­ç»ƒã€æ¨¡å‹åˆå¹¶ã€éƒ¨ç½²æœåŠ¡ï¼ˆæµ‹è¯•ä¸­ï¼‰ï¼›
æ”¯æŒapiæ–¹å¼ï¼Œå¾®è°ƒè®­ç»ƒã€æ¨¡å‹åˆå¹¶ã€æ¨¡å‹å‘å¸ƒï¼›
å¢åŠ æ•°æ®ç®¡ç†ï¼Œæ”¯æŒä¸Šä¼ excelæ–‡ä»¶ï¼›
å¢åŠ è®­ç»ƒè„šæœ¬ç®¡ç†ï¼Œæ”¯æŒè‡ªå®šä¹‰è„šæœ¬ç¼–è¾‘å’Œè®­ç»ƒï¼Œæ”¯æŒpt/sft/rm/ppo/dpoè®­ç»ƒé˜¶æ®µï¼Œæ”¯æŒtrain/eval/predictä»»åŠ¡ï¼›
å¢åŠ æ¨¡å‹å¿«é€Ÿç¼–è¾‘èƒ½åŠ›ï¼Œèƒ½å¤Ÿç¼–è¾‘æŒ‡å®šé—®é¢˜çš„å›ç­”ï¼›


## æ¨¡å‹

| æ¨¡å‹å                                                   | æ¨¡å‹å¤§å°                     | é»˜è®¤æ¨¡å—           | Template  |
| -------------------------------------------------------- | --------------------------- | ----------------- | --------- |
| [Baichuan](https://github.com/baichuan-inc/Baichuan-13B) | 7B/13B                      | W_pack            | baichuan  |
| [Baichuan2](https://github.com/baichuan-inc/Baichuan2)   | 7B/13B                      | W_pack            | baichuan2 |
| [BLOOM](https://huggingface.co/bigscience/bloom)         | 560M/1.1B/1.7B/3B/7.1B/176B | query_key_value   | -         |
| [BLOOMZ](https://huggingface.co/bigscience/bloomz)       | 560M/1.1B/1.7B/3B/7.1B/176B | query_key_value   | -         |
| [ChatGLM3](https://github.com/THUDM/ChatGLM3)            | 6B                          | query_key_value   | chatglm3  |
| [Falcon](https://huggingface.co/tiiuae/falcon-7b)        | 7B/40B/180B                 | query_key_value   | falcon    |
| [InternLM](https://github.com/InternLM/InternLM)         | 7B/20B                      | q_proj,v_proj     | intern    |
| [LLaMA](https://github.com/facebookresearch/llama)       | 7B/13B/33B/65B              | q_proj,v_proj     | -         |
| [LLaMA-2](https://huggingface.co/meta-llama)             | 7B/13B/70B                  | q_proj,v_proj     | llama2    |
| [Mistral](https://huggingface.co/mistralai)              | 7B                          | q_proj,v_proj     | mistral   |
| [Phi-1.5](https://huggingface.co/microsoft/phi-1_5)      | 1.3B                        | Wqkv              | -         |
| [Qwen](https://github.com/QwenLM/Qwen)                   | 7B/14B                      | c_attn            | qwen      |
| [XVERSE](https://github.com/xverse-ai)                   | 7B/13B/65B                  | q_proj,v_proj     | xverse    |



## è½¯ä»¶ä¾èµ–

- Python 3.10 å’Œ PyTorch 1.13.1
- ğŸ¤—Transformers, Datasets, Accelerate, PEFT å’Œ TRL
- sentencepiece, protobuf å’Œ tiktoken
- jieba, rouge-chinese å’Œ nltk (ç”¨äºè¯„ä¼°)
- gradio å’Œ matplotlib (ç”¨äºç½‘é¡µç«¯äº¤äº’)
- uvicorn, fastapi å’Œ sse-starlette (ç”¨äº API)


## ç›®å½•è¯´æ˜
- main.py              # FastAPIåº”ç”¨ç¨‹åº
- bin/                 # ç¨‹åºè„šæœ¬
- config/                 # é…ç½®æ–‡ä»¶
- data                 # æ•°æ®æ–‡ä»¶
- doc/                 # æ–‡æ¡£
- lib/                 # é¢å¤–ä¾èµ–
- llm/                 # å¤§æ¨¡å‹æƒé‡
- logs/                # æ—¥å¿—ç›®å½•
- scripts/             # è®­ç»ƒè„šæœ¬
- templates/           # htmlæ¨¡æ¿
- trainer/                # åº”ç”¨ä»£ç 
    - api/                 # api
    - model/                 # å¯¹è±¡
    - service/                 #æœåŠ¡
    - settings.py                 #é…ç½®


## é¡¹ç›®å¯åŠ¨

https://github.com/simonlisiyu/llm_finetune/blob/main/doc/HOW_TO_START.md

## é¡¹ç›®ä½¿ç”¨

https://github.com/simonlisiyu/llm_finetune/blob/main/doc/HOW_TO_USE.md

## é…ç½®æ–‡ä»¶
- config/trainer.yaml  # æœåŠ¡é…ç½®æ–‡ä»¶
- scripts/src/llmtuner/llmtuner_settings # è®­ç»ƒè„šæœ¬é…ç½®æ–‡ä»¶
- config/model_info.json  # æ¨¡å‹é…ç½®æ–‡ä»¶
- data/dataset_info.json  # æ•°æ®é›†é…ç½®æ–‡ä»¶

### é…ç½®æ–‡ä»¶æ³¨æ„ï¼šbase_dirç­‰ä¿®æ”¹æ­£ç¡®ã€‚
### ç¯å¢ƒæ³¨æ„ï¼šå¯åŠ¨ä¼šä¾èµ–ç¯å¢ƒï¼Œç›®å½•åŠæ–‡ä»¶éœ€è¦æå‰åˆ›å»ºå¥½ã€‚

## docker
å¾…æµ‹è¯•åè¡¥å……


## æœåŠ¡éªŒè¯
### webæœåŠ¡
> http://localhost:8000/docs

### é¦–é¡µ
> http://localhost:8000




## åè®®

æœ¬ä»“åº“çš„ä»£ç ä¾ç…§ [Apache-2.0](LICENSE) åè®®å¼€æºã€‚

ä½¿ç”¨æ¨¡å‹æƒé‡æ—¶ï¼Œè¯·éµå¾ªå¯¹åº”çš„æ¨¡å‹åè®®ï¼š

- [LLaMA](https://github.com/facebookresearch/llama/blob/main/MODEL_CARD.md)
- [LLaMA-2](https://ai.meta.com/llama/license/)
- [BLOOM](https://huggingface.co/spaces/bigscience/license)
- [Falcon](LICENSE)
- [Baichuan](https://huggingface.co/baichuan-inc/baichuan-7B/resolve/main/baichuan-7B%20%E6%A8%A1%E5%9E%8B%E8%AE%B8%E5%8F%AF%E5%8D%8F%E8%AE%AE.pdf)
- [Baichuan2](https://huggingface.co/baichuan-inc/Baichuan2-7B-Base/resolve/main/Baichuan%202%E6%A8%A1%E5%9E%8B%E7%A4%BE%E5%8C%BA%E8%AE%B8%E5%8F%AF%E5%8D%8F%E8%AE%AE.pdf)
- [InternLM](https://github.com/InternLM/InternLM#open-source-license)
- [Qwen](https://huggingface.co/Qwen/Qwen-7B-Chat/blob/main/LICENSE)
- [XVERSE](https://github.com/xverse-ai/XVERSE-13B/blob/main/MODEL_LICENSE.pdf)
- [ChatGLM2](https://github.com/THUDM/ChatGLM2-6B/blob/main/MODEL_LICENSE)
- [Phi-1.5](https://huggingface.co/microsoft/phi-1_5/resolve/main/Research%20License.docx)


## è‡´è°¢

æœ¬é¡¹ç›®å—ç›Šäº [LLaMA-Efficient-Tuning](https://github.com/hiyouga/LLaMA-Efficient-Tuning)ï¼Œæ„Ÿè°¢ä½œè€…çš„ä»˜å‡ºã€‚

