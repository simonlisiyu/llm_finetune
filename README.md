# LLM Finetune

[![GitHub Code License](https://img.shields.io/github/license/simonlisiyu/llm_finetune)](LICENSE)
[![GitHub last commit](https://img.shields.io/github/last-commit/simonlisiyu/llm_finetune)](https://github.com/simonlisiyu/llm_finetune/commits/main)

ğŸ‘‹ åŠ æˆ‘çš„[å¾®ä¿¡](wechat.jpg)ã€‚

## æ›´æ–°æ—¥å¿—

[23/10/28]
ä»£ç é‡æ„ï¼Œæ”¯æŒæ•´ä½“ä»£ç æ•´åˆåˆ°alita-traineré‡Œï¼›
yamlé…ç½®æ–‡ä»¶ç²¾ç®€è§„æ•´ï¼Œå¤šæ¨¡å‹çš„è®­ç»ƒã€åˆå¹¶è„šæœ¬åˆå¹¶ç»Ÿä¸€ï¼›
æ¨¡å‹éƒ¨ç½²æœåŠ¡bugä¿®å¤ï¼›
æ”¯æŒå¤§æ¨¡å‹è¯„ä¼°ï¼Œæ”¯æŒBLEU-4ã€ROUGE-1/2/Lï¼›
æ”¯æŒå¾®è°ƒè®­ç»ƒåçš„å¤§æ¨¡å‹ä½œä¸ºè®­ç»ƒæ¨¡å‹å†è®­ç»ƒï¼›
ç³»ç»Ÿç›‘æ§é™¤gpuï¼Œæ”¯æŒcpuã€memå’Œdiskç›‘æ§ï¼›

[23/09/28]
æ”¯æŒbaichuanã€llama2ã€llamaã€glm2ç­‰å¤§æ¨¡å‹ï¼Œæ”¯æŒQLoRAï¼›
æ”¯æŒgpué¢„è§ˆã€å¤§æ¨¡å‹å¾®è°ƒè®­ç»ƒã€æ¨¡å‹åˆå¹¶ã€éƒ¨ç½²æœåŠ¡ï¼ˆæµ‹è¯•ä¸­ï¼‰ï¼›
æ”¯æŒapiæ–¹å¼ï¼Œå¾®è°ƒè®­ç»ƒã€æ¨¡å‹åˆå¹¶ã€æ¨¡å‹å‘å¸ƒï¼›
å¢åŠ æ•°æ®ç®¡ç†ï¼Œæ”¯æŒä¸Šä¼ excelæ–‡ä»¶ï¼›
å¢åŠ è®­ç»ƒè„šæœ¬ç®¡ç†ï¼Œæ”¯æŒè‡ªå®šä¹‰è„šæœ¬ç¼–è¾‘å’Œè®­ç»ƒï¼Œæ”¯æŒpt/sft/rm/ppo/dpoè®­ç»ƒé˜¶æ®µï¼Œæ”¯æŒtrain/eval/predictä»»åŠ¡ï¼›
å¢åŠ æ¨¡å‹å¿«é€Ÿç¼–è¾‘èƒ½åŠ›ï¼Œèƒ½å¤Ÿç¼–è¾‘æŒ‡å®šé—®é¢˜çš„å›ç­”ï¼›


## æ¨¡å‹

| æ¨¡å‹å                                                   | æ¨¡å‹å¤§å°                     | é»˜è®¤æ¨¡å—           | Template  |
| -------------------------------------------------------- | --------------------------- | ----------------- | --------- |
| [LLaMA](https://github.com/facebookresearch/llama)       | 7B/13B/33B/65B              | q_proj,v_proj     | -         |
| [LLaMA-2](https://huggingface.co/meta-llama)             | 7B/13B/70B                  | q_proj,v_proj     | llama2    |
| [BLOOM](https://huggingface.co/bigscience/bloom)         | 560M/1.1B/1.7B/3B/7.1B/176B | query_key_value   | -         |
| [BLOOMZ](https://huggingface.co/bigscience/bloomz)       | 560M/1.1B/1.7B/3B/7.1B/176B | query_key_value   | -         |
| [Falcon](https://huggingface.co/tiiuae/falcon-7b)        | 7B/40B                      | query_key_value   | -         |
| [Baichuan](https://github.com/baichuan-inc/Baichuan-13B) | 7B/13B                      | W_pack            | baichuan  |
| [Baichuan2](https://github.com/baichuan-inc/Baichuan2)   | 7B/13B                      | W_pack            | baichuan2 |
| [InternLM](https://github.com/InternLM/InternLM)         | 7B/20B                      | q_proj,v_proj     | intern    |
| [Qwen](https://github.com/QwenLM/Qwen-7B)                | 7B/14B                      | c_attn            | chatml    |
| [XVERSE](https://github.com/xverse-ai/XVERSE-13B)        | 13B                         | q_proj,v_proj     | xverse    |
| [ChatGLM2](https://github.com/THUDM/ChatGLM2-6B)         | 6B                          | query_key_value   | chatglm2  |
| [Phi-1.5](https://huggingface.co/microsoft/phi-1_5)      | 1.3B                        | Wqkv              | -         |



## è½¯ä»¶ä¾èµ–

- Python 3.10 å’Œ PyTorch 1.13.1
- ğŸ¤—Transformers, Datasets, Accelerate, PEFT å’Œ TRL
- sentencepiece, protobuf å’Œ tiktoken
- jieba, rouge-chinese å’Œ nltk (ç”¨äºè¯„ä¼°)
- gradio å’Œ matplotlib (ç”¨äºç½‘é¡µç«¯äº¤äº’)
- uvicorn, fastapi å’Œ sse-starlette (ç”¨äº API)


## ç›®å½•è¯´æ˜
- main.py              # FastAPIåº”ç”¨ç¨‹åº
- bin/                 # ç¨‹åºè„šæœ¬
- config/                 # é…ç½®æ–‡ä»¶
- data                 # æ•°æ®æ–‡ä»¶
- doc/                 # æ–‡æ¡£
- lib/                 # é¢å¤–ä¾èµ–
- llm/                 # å¤§æ¨¡å‹æƒé‡
- logs/                # æ—¥å¿—ç›®å½•
- scripts/             # è®­ç»ƒè„šæœ¬
- templates/           # htmlæ¨¡æ¿
- trainer/                # åº”ç”¨ä»£ç 
    - api/                 # api
    - model/                 # å¯¹è±¡
    - service/                 #æœåŠ¡
    - settings.py                 #é…ç½®


## é¡¹ç›®å¯åŠ¨

https://github.com/simonlisiyu/llm_finetune/blob/main/doc/HOW_TO_START.md

## é¡¹ç›®ä½¿ç”¨

https://github.com/simonlisiyu/llm_finetune/blob/main/doc/HOW_TO_USE.md

## é…ç½®æ–‡ä»¶
- config/trainer.yaml  # æœåŠ¡é…ç½®æ–‡ä»¶
- scripts/src/llmtuner/llmtuner_settings # è®­ç»ƒè„šæœ¬é…ç½®æ–‡ä»¶
- config/model_info.json  # æ¨¡å‹é…ç½®æ–‡ä»¶
- data/dataset_info.json  # æ•°æ®é›†é…ç½®æ–‡ä»¶

### é…ç½®æ–‡ä»¶æ³¨æ„ï¼šbase_dirç­‰ä¿®æ”¹æ­£ç¡®ã€‚
### ç¯å¢ƒæ³¨æ„ï¼šå¯åŠ¨ä¼šä¾èµ–ç¯å¢ƒï¼Œç›®å½•åŠæ–‡ä»¶éœ€è¦æå‰åˆ›å»ºå¥½ã€‚

## docker
### æ„å»ºé•œåƒ
> docker build -t docker.li.com/llm_finetune .
### è¿è¡Œå®¹å™¨
> docker run --gpus all --network host --ipc host --name llm_finetune -d \
--ulimit memlock=-1 --ulimit stack=67108864 \
-v /data0/service/llm_finetune/config/171.trainer.yaml:/app/config/trainer.yaml \
-v /data0/LLMs/model_info.json:/app/config/model_info.json \
-v /var/run/docker.sock:/var/run/docker.sock \
-v /data0/LLMs:/app/llm \
-v /data0/logs/llm_finetune:/app/logs \
-v /data0/data/llm_finetune:/app/data \
--security-opt seccomp=unconfined \
docker.li.com/llm_finetune

### dockerç¯å¢ƒæ³¨æ„ï¼š-vä¹‹åï¼Œtrainer.yamlé…ç½®å®¹å™¨å†…ç›®å½•åŠæ–‡ä»¶ã€‚

## æœåŠ¡éªŒè¯
### webæœåŠ¡
> http://localhost:8000/docs

### é¦–é¡µ
> http://localhost:8000

### ç¦»çº¿é¡¹ç›®ç¯å¢ƒ
```shell
docker save docker.li.com/llm_finetune -o ./llm_finetune.img
tar -czvf llm_finetune.img.tgz llm_finetune.img

tar -zxvf llm_finetune.img.tgz
docker load --input llm_finetune.img
docker images
```


### æµè§ˆå™¨æµ‹è¯•

```bash
python src/web_demo.py \
    --model_name_or_path path_to_llama_model \
    --template default \
    --finetuning_type lora \
    --checkpoint_dir path_to_checkpoint
```



## åè®®

æœ¬ä»“åº“çš„ä»£ç ä¾ç…§ [Apache-2.0](LICENSE) åè®®å¼€æºã€‚

ä½¿ç”¨æ¨¡å‹æƒé‡æ—¶ï¼Œè¯·éµå¾ªå¯¹åº”çš„æ¨¡å‹åè®®ï¼š

- [LLaMA](https://github.com/facebookresearch/llama/blob/main/MODEL_CARD.md)
- [LLaMA-2](https://ai.meta.com/llama/license/)
- [BLOOM](https://huggingface.co/spaces/bigscience/license)
- [Falcon](LICENSE)
- [Baichuan](https://huggingface.co/baichuan-inc/baichuan-7B/resolve/main/baichuan-7B%20%E6%A8%A1%E5%9E%8B%E8%AE%B8%E5%8F%AF%E5%8D%8F%E8%AE%AE.pdf)
- [Baichuan2](https://huggingface.co/baichuan-inc/Baichuan2-7B-Base/resolve/main/Baichuan%202%E6%A8%A1%E5%9E%8B%E7%A4%BE%E5%8C%BA%E8%AE%B8%E5%8F%AF%E5%8D%8F%E8%AE%AE.pdf)
- [InternLM](https://github.com/InternLM/InternLM#open-source-license)
- [Qwen](https://huggingface.co/Qwen/Qwen-7B-Chat/blob/main/LICENSE)
- [XVERSE](https://github.com/xverse-ai/XVERSE-13B/blob/main/MODEL_LICENSE.pdf)
- [ChatGLM2](https://github.com/THUDM/ChatGLM2-6B/blob/main/MODEL_LICENSE)
- [Phi-1.5](https://huggingface.co/microsoft/phi-1_5/resolve/main/Research%20License.docx)


## è‡´è°¢

æœ¬é¡¹ç›®å—ç›Šäº [LLaMA-Efficient-Tuning](https://github.com/hiyouga/LLaMA-Efficient-Tuning)ï¼Œæ„Ÿè°¢ä½œè€…çš„ä»˜å‡ºã€‚

